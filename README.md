# Pinterest Data Pipeline

An end-to-end data processing pipeline that ingests data from an API simulating users posting on Pinterest, cleans and processes the data into batch and stream pipelines and stores them into a data lake and PostgreSQL database respectively.

Technologies used (so far): 
Python -> Programming 
Apache Kafka -> Data Ingestion 
Apache Spark (Pyspark) -> Batch Data Processing
Apache Airflow -> Orchestrating Batch Processing Job
AWS S3/Boto3 -> Storage of Batch Data
PostgreSQL -> Storage of Stream Data

### Installation instructions
### Usage instructions
### File structure of the project
### License information